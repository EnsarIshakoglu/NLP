{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "NLP Text Classification",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EnsarIshakoglu/NLP/blob/topic-modelling/NLP_Text_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "935329e7-815b-4377-874b-38ca768865f2",
        "_cell_guid": "f7832109-87a9-4266-bb22-e819083e084c",
        "execution": {
          "iopub.status.busy": "2021-11-18T08:52:35.870893Z",
          "iopub.execute_input": "2021-11-18T08:52:35.871339Z",
          "iopub.status.idle": "2021-11-18T08:52:42.798162Z",
          "shell.execute_reply.started": "2021-11-18T08:52:35.871298Z",
          "shell.execute_reply": "2021-11-18T08:52:42.797316Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqfVPrH9T3bd",
        "outputId": "42ae3d9c-e54f-48e7-b48f-998d00692507"
      },
      "source": [
        "# Source: https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/#1introduction\n",
        "# Run in python console\n",
        "import nltk; nltk.download('stopwords')\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Run in terminal or command prompt\n",
        "!python3 -m spacy download en\n",
        "\n",
        "# SKlearn\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.model_selection import cross_val_score\n",
        "# from sklearn.model_selection import KFold\n",
        "# from sklearn.preprocessing import MinMaxScaler\n",
        "# from sklearn.preprocessing import LabelEncoder\n",
        "# from sklearn.feature_extraction.text import CountVectorizer\n",
        "# from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Data processing\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Stackapi to fetch stackoverflow api\n",
        "!pip install stackapi\n",
        "from stackapi import StackAPI\n",
        "\n",
        "from pprint import pprint\n",
        "\n",
        "# Gensim\n",
        "!pip install gensim==3.8.3\n",
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models import CoherenceModel\n",
        "\n",
        "# spacy for lemmatization\n",
        "import spacy\n",
        "\n",
        "# Plotting tools\n",
        "!pip install pyLDAvis\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim_models as gensimvis\n",
        "\n",
        "# Enable logging for gensim - optional\n",
        "import logging\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "Collecting en_core_web_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz (12.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.0 MB 5.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.62.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.21.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.6)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.10.0.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n",
            "Requirement already satisfied: stackapi in /usr/local/lib/python3.7/dist-packages (0.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from stackapi) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from stackapi) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->stackapi) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->stackapi) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->stackapi) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->stackapi) (2.10)\n",
            "Requirement already satisfied: gensim==3.8.3 in /usr/local/lib/python3.7/dist-packages (3.8.3)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.3) (5.2.1)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.3) (1.4.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.3) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.3) (1.21.4)\n",
            "Requirement already satisfied: pyLDAvis in /usr/local/lib/python3.7/dist-packages (3.3.1)\n",
            "Requirement already satisfied: funcy in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.16)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (57.4.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (2.11.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.4.1)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.0)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (3.8.3)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.3.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.0.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.1.0)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (2.7.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.16.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.21.4)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyLDAvis) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyLDAvis) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.0->pyLDAvis) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim->pyLDAvis) (5.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->pyLDAvis) (2.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyLDAvis) (3.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cX5X4xhqabeI"
      },
      "source": [
        "### Mount colab drive to google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGt6RbgySmTR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "219264ed-b3d7-49e3-fbdd-50b54f94f8a1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "cd8ab0fa-e99a-4837-9d07-6bedca16f4ad",
        "_cell_guid": "27a0b46b-904c-48ef-946f-970a6d0f4fb6",
        "trusted": true,
        "id": "bG7FuSZMT3bk"
      },
      "source": [
        "## Fetch data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHjpvi1MWTPJ"
      },
      "source": [
        "# Get the data from stackoverflow sorted by votes\n",
        "def fetch_data():\n",
        "  if not exists('/content/NLP-question-data'):\n",
        "    !git clone https://github.com/EnsarIshakoglu/NLP-question-data.git\n",
        "  \n",
        "  data = pd.read_csv('/content/NLP-question-data/questions.csv')\n",
        "  \n",
        "  return data"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZWjtjucXZk1"
      },
      "source": [
        "## Remove useless data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmY-K07YW_FI"
      },
      "source": [
        "def clean_data(df):  \n",
        "  df = df[['tags', 'body']]\n",
        "\n",
        "  # Strip html tags with regex:\n",
        "  df['body'] = df['body'].str.replace(r'<[^<>]*>', '', regex=True)\n",
        "\n",
        "  # Get first tag for multi-class classification\n",
        "  row_count = df.shape[0]\n",
        "\n",
        "  # for i in range(row_count):\n",
        "  #   df['tags'].iloc[i] = df['tags'].iloc[i][0]\n",
        "  return df"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ft2veo6bajpz"
      },
      "source": [
        "### Create folder and file from df, unmout drive after"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXasm52uSns_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 685
        },
        "outputId": "868d5407-17b1-45f4-f3d3-e70e25928e27"
      },
      "source": [
        "from os.path import exists\n",
        "\n",
        "!mkdir stackoverflow\n",
        "\n",
        "if not exists('/content/stackoverflow/questions.csv') or not exists('/content/NLP-question-data'):\n",
        "  df = fetch_data()[['tags', 'body']]\n",
        "  df = clean_data(df)\n",
        "  # df.to_csv('/content/stackoverflow/questions.csv')\n",
        "  print(\"Fetched data from stackoverflow, removed the useless data and saved it in stackoverflow/questions.csv\")\n",
        "\n",
        "drive.flush_and_unmount()\n",
        "df"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘stackoverflow’: File exists\n",
            "Fetched data from stackoverflow, removed the useless data and saved it in stackoverflow/questions.csv\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_repr_html_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m         \"\"\"\n\u001b[1;32m    800\u001b[0m         \u001b[0mReturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtuple\u001b[0m \u001b[0mrepresenting\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdimensionality\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mto_html\u001b[0;34m(self, buf, encoding, classes, notebook, border)\u001b[0m\n\u001b[1;32m    986\u001b[0m         \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m         \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mlist\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mtuple\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 988\u001b[0;31m         \u001b[0mnotebook\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    989\u001b[0m         \u001b[0mborder\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    990\u001b[0m         \u001b[0mtable_id\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NotebookFormatter' object has no attribute 'get_result'"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    tags                                               body\n",
              "0      ['java', 'c++', 'performance', 'cpu-architectu...  Here is a piece of C++ code that shows some ve...\n",
              "1       ['git', 'version-control', 'git-commit', 'undo']  I accidentally committed the wrong files to Gi...\n",
              "2      ['git', 'version-control', 'git-branch', 'git-...  I want to delete a branch both locally and rem...\n",
              "3      ['git', 'version-control', 'git-pull', 'git-fe...  What are the differences between git pull and ...\n",
              "4      ['python', 'iterator', 'generator', 'yield', '...  What is the use of the yield keyword in Python...\n",
              "...                                                  ...                                                ...\n",
              "17495           ['python', 'pandas', 'dataframe', 'nan']  I have a Pandas Dataframe as below:\\n      itm...\n",
              "17496        ['java', 'datetime', 'java-8', 'java-time']  What is the best way to convert a java.util.Da...\n",
              "17497                             ['visual-studio-code']  Is there a Compare feature like the Plugin for...\n",
              "17498  ['visual-studio-code', 'whitespace', 'vscode-s...  Is it possible to show whitespace characters, ...\n",
              "17499                                         ['docker']  Running the docker registry with below command...\n",
              "\n",
              "[17500 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlrQln74au2T"
      },
      "source": [
        "### Load file from drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "f76b7aed-1453-43c3-8fd6-b5b2975745c5",
        "_cell_guid": "93e5cfbc-0042-418d-975e-49198d762bbc",
        "execution": {
          "iopub.status.busy": "2021-11-18T08:56:42.617124Z",
          "iopub.execute_input": "2021-11-18T08:56:42.617630Z",
          "iopub.status.idle": "2021-11-18T08:56:42.628289Z",
          "shell.execute_reply.started": "2021-11-18T08:56:42.617593Z",
          "shell.execute_reply": "2021-11-18T08:56:42.627547Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true,
        "id": "ddE71wzjT3bt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "655a58d8-a818-4e0c-ece8-0445d7a3ebd4"
      },
      "source": [
        "print(f\"There are {len(df['body'].unique())} rows in the dataset.\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 3900 rows in the dataset.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "9bd0590f-4430-49f9-9af6-e53a65efcc84",
        "_cell_guid": "56e348ea-0b56-460a-9886-15594c5a4022",
        "execution": {
          "iopub.status.busy": "2021-11-18T08:56:42.630012Z",
          "iopub.execute_input": "2021-11-18T08:56:42.630495Z",
          "iopub.status.idle": "2021-11-18T08:56:42.638376Z",
          "shell.execute_reply.started": "2021-11-18T08:56:42.630460Z",
          "shell.execute_reply": "2021-11-18T08:56:42.637643Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true,
        "id": "91v21KDhT3bt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae573821-9f09-4be9-98d4-b0ec9fcfbb65"
      },
      "source": [
        "df = df[~df['body'].duplicated()]\n",
        "print(f\"There are {len(df)} rows in the deduplicated dataset.\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 3900 rows in the deduplicated dataset.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltXOxcQdajL6"
      },
      "source": [
        "## Topic modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9ZzAtKGazed"
      },
      "source": [
        "# NLTK Stop words\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')\n",
        "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "3e47d8d7-b296-445c-bd20-e47dc836ba32",
        "_cell_guid": "939331e3-43f2-4025-bf1b-05d4f930c062",
        "trusted": true,
        "id": "iFV12cSlT3bz"
      },
      "source": [
        "## Prepare data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfviMYofJ8n_",
        "outputId": "284ef07a-3b40-4a45-d7a6-ef855e4ca706"
      },
      "source": [
        "def sent_to_words(sentences):\n",
        "    for sentence in sentences:\n",
        "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
        "\n",
        "data_words = list(sent_to_words(df['body']))\n",
        "\n",
        "print(data_words[:1])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['here', 'is', 'piece', 'of', 'code', 'that', 'shows', 'some', 'very', 'peculiar', 'behavior', 'for', 'some', 'strange', 'reason', 'sorting', 'the', 'data', 'before', 'the', 'timed', 'region', 'miraculously', 'makes', 'the', 'loop', 'almost', 'six', 'times', 'faster', 'include', 'lt', 'algorithm', 'gt', 'include', 'lt', 'ctime', 'gt', 'include', 'lt', 'iostream', 'gt', 'int', 'main', 'generate', 'data', 'const', 'unsigned', 'arraysize', 'int', 'data', 'arraysize', 'for', 'unsigned', 'lt', 'arraysize', 'data', 'std', 'rand', 'with', 'this', 'the', 'next', 'loop', 'runs', 'faster', 'std', 'sort', 'data', 'data', 'arraysize', 'test', 'clock_t', 'start', 'clock', 'long', 'long', 'sum', 'for', 'unsigned', 'lt', 'for', 'unsigned', 'lt', 'arraysize', 'primary', 'loop', 'if', 'data', 'gt', 'sum', 'data', 'double', 'elapsedtime', 'static_cast', 'lt', 'double', 'gt', 'clock', 'start', 'clocks_per_sec', 'std', 'cout', 'lt', 'lt', 'elapsedtime', 'lt', 'lt', 'std', 'cout', 'lt', 'lt', 'quot', 'sum', 'quot', 'lt', 'lt', 'sum', 'lt', 'lt', 'without', 'std', 'sort', 'data', 'data', 'arraysize', 'the', 'code', 'runs', 'in', 'seconds', 'with', 'the', 'sorted', 'data', 'the', 'code', 'runs', 'in', 'seconds', 'sorting', 'itself', 'takes', 'more', 'time', 'than', 'this', 'one', 'pass', 'over', 'the', 'array', 'so', 'it', 'not', 'actually', 'worth', 'doing', 'if', 'we', 'needed', 'to', 'calculate', 'this', 'for', 'an', 'unknown', 'array', 'initially', 'thought', 'this', 'might', 'be', 'just', 'language', 'or', 'compiler', 'anomaly', 'so', 'tried', 'java', 'import', 'java', 'util', 'arrays', 'import', 'java', 'util', 'random', 'public', 'class', 'main', 'public', 'static', 'void', 'main', 'string', 'args', 'generate', 'data', 'int', 'arraysize', 'int', 'data', 'new', 'int', 'arraysize', 'random', 'rnd', 'new', 'random', 'for', 'int', 'lt', 'arraysize', 'data', 'rnd', 'nextint', 'with', 'this', 'the', 'next', 'loop', 'runs', 'faster', 'arrays', 'sort', 'data', 'test', 'long', 'start', 'system', 'nanotime', 'long', 'sum', 'for', 'int', 'lt', 'for', 'int', 'lt', 'arraysize', 'primary', 'loop', 'if', 'data', 'gt', 'sum', 'data', 'system', 'out', 'println', 'system', 'nanotime', 'start', 'system', 'out', 'println', 'quot', 'sum', 'quot', 'sum', 'with', 'similar', 'but', 'less', 'extreme', 'result', 'my', 'first', 'thought', 'was', 'that', 'sorting', 'brings', 'the', 'data', 'into', 'the', 'cache', 'but', 'then', 'thought', 'how', 'silly', 'that', 'was', 'because', 'the', 'array', 'was', 'just', 'generated', 'what', 'is', 'going', 'on', 'why', 'is', 'processing', 'sorted', 'array', 'faster', 'than', 'processing', 'an', 'unsorted', 'array', 'the', 'code', 'is', 'summing', 'up', 'some', 'independent', 'terms', 'so', 'the', 'order', 'should', 'not', 'matter', 'related', 'followup', 'amp', 'as', 'about', 'the', 'same', 'effect', 'with', 'different', 'later', 'compilers', 'and', 'options', 'why', 'is', 'processing', 'an', 'unsorted', 'array', 'the', 'same', 'speed', 'as', 'processing', 'sorted', 'array', 'with', 'modern', 'clang', 'gcc', 'optimization', 'flag', 'makes', 'code', 'slower', 'than']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iq09UbKLbtfI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9111c5d5-4006-46ef-cae1-1577340fbe13"
      },
      "source": [
        "# Build the bigram and trigram models\n",
        "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
        "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
        "\n",
        "# Faster way to get a sentence clubbed as a trigram/bigram\n",
        "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
        "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
        "\n",
        "# See trigram example\n",
        "print(trigram_mod[bigram_mod[data_words[0]]])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['here', 'is', 'piece', 'of', 'code', 'that', 'shows', 'some', 'very', 'peculiar', 'behavior', 'for', 'some', 'strange', 'reason', 'sorting', 'the', 'data', 'before', 'the', 'timed', 'region', 'miraculously', 'makes', 'the', 'loop', 'almost', 'six', 'times', 'faster', 'include', 'lt', 'algorithm', 'gt', 'include', 'lt', 'ctime', 'gt', 'include', 'lt', 'iostream', 'gt', 'int', 'main', 'generate', 'data', 'const', 'unsigned', 'arraysize', 'int', 'data', 'arraysize', 'for', 'unsigned', 'lt', 'arraysize', 'data', 'std', 'rand', 'with', 'this', 'the', 'next', 'loop', 'runs', 'faster', 'std', 'sort', 'data', 'data', 'arraysize', 'test', 'clock_t', 'start', 'clock', 'long', 'long', 'sum', 'for', 'unsigned', 'lt', 'for', 'unsigned', 'lt', 'arraysize', 'primary', 'loop', 'if', 'data', 'gt', 'sum', 'data', 'double', 'elapsedtime', 'static_cast', 'lt', 'double', 'gt', 'clock', 'start', 'clocks_per_sec', 'std_cout', 'lt', 'lt', 'elapsedtime', 'lt', 'lt', 'std_cout', 'lt', 'lt', 'quot', 'sum', 'quot', 'lt', 'lt', 'sum', 'lt', 'lt', 'without', 'std', 'sort', 'data', 'data', 'arraysize', 'the', 'code', 'runs', 'in', 'seconds', 'with', 'the', 'sorted', 'data', 'the', 'code', 'runs', 'in', 'seconds', 'sorting', 'itself', 'takes', 'more', 'time', 'than', 'this', 'one', 'pass', 'over', 'the', 'array', 'so', 'it', 'not', 'actually', 'worth', 'doing', 'if', 'we', 'needed', 'to', 'calculate', 'this', 'for', 'an', 'unknown', 'array', 'initially', 'thought', 'this', 'might', 'be', 'just', 'language', 'or', 'compiler', 'anomaly', 'so', 'tried', 'java', 'import', 'java_util', 'arrays', 'import', 'java_util', 'random', 'public', 'class', 'main', 'public', 'static_void', 'main', 'string', 'args', 'generate', 'data', 'int', 'arraysize', 'int', 'data', 'new', 'int', 'arraysize', 'random', 'rnd', 'new', 'random', 'for', 'int', 'lt', 'arraysize', 'data', 'rnd', 'nextint', 'with', 'this', 'the', 'next', 'loop', 'runs', 'faster', 'arrays', 'sort', 'data', 'test', 'long', 'start', 'system', 'nanotime', 'long', 'sum', 'for', 'int', 'lt', 'for', 'int', 'lt', 'arraysize', 'primary', 'loop', 'if', 'data', 'gt', 'sum', 'data', 'system_out_println', 'system', 'nanotime', 'start', 'system_out_println', 'quot', 'sum', 'quot', 'sum', 'with', 'similar', 'but', 'less', 'extreme', 'result', 'my', 'first', 'thought', 'was', 'that', 'sorting', 'brings', 'the', 'data', 'into', 'the', 'cache', 'but', 'then', 'thought', 'how', 'silly', 'that', 'was', 'because', 'the', 'array', 'was', 'just', 'generated', 'what', 'is', 'going', 'on', 'why', 'is', 'processing', 'sorted', 'array', 'faster_than', 'processing', 'an', 'unsorted', 'array', 'the', 'code', 'is', 'summing', 'up', 'some', 'independent', 'terms', 'so', 'the', 'order', 'should', 'not', 'matter', 'related', 'followup', 'amp', 'as', 'about', 'the', 'same', 'effect', 'with', 'different', 'later', 'compilers', 'and', 'options', 'why', 'is', 'processing', 'an', 'unsorted', 'array', 'the', 'same', 'speed', 'as', 'processing', 'sorted', 'array', 'with', 'modern', 'clang', 'gcc', 'optimization', 'flag', 'makes', 'code', 'slower_than']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2leEJMubs1u"
      },
      "source": [
        "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
        "def remove_stopwords(texts):\n",
        "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
        "\n",
        "def make_bigrams(texts):\n",
        "    return [bigram_mod[doc] for doc in texts]\n",
        "\n",
        "def make_trigrams(texts):\n",
        "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
        "\n",
        "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
        "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
        "    texts_out = []\n",
        "    for sent in texts:\n",
        "        doc = nlp(\" \".join(sent)) \n",
        "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
        "    return texts_out"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1-HG7WvcJX4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22bc6966-06b1-4a8f-ae22-32e24fd0c50f"
      },
      "source": [
        "# Remove Stop Words\n",
        "data_words_nostops = remove_stopwords(data_words)\n",
        "\n",
        "# Form Bigrams\n",
        "data_words_bigrams = make_bigrams(data_words_nostops)\n",
        "\n",
        "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
        "# python3 -m spacy download en\n",
        "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
        "\n",
        "# Do lemmatization keeping only noun, adj, vb, adv\n",
        "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'ADV'])\n",
        "\n",
        "print(data_lemmatized[:1])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['piece', 'code', 'peculiar', 'behavior', 'strange', 'reason', 'datum', 'region', 'miraculously', 'loop', 'almost', 'time', 'faster', 'main', 'generate', 'datum', 'const', 'datum', 'loop', 'fast', 'datum', 'datum', 'test', 'clock', 'long', 'long', 'sum', 'datum', 'double', 'elapsedtime', 'lt', 'double', 'clock', 'start', 'datum', 'second', 'code', 'second', 'time', 'pass', 'array', 'actually', 'worth', 'calculate', 'unknown', 'array', 'initially', 'compiler', 'random', 'public', 'class', 'main', 'public', 'static', 'void', 'main', 'string', 'arg', 'generate', 'datum', 'int', 'next', 'fast', 'test', 'long', 'start', 'system', 'nanotime', 'long', 'sum', 'lt', 'system', 'println', 'system', 'start', 'system', 'similar', 'less', 'extreme', 'result', 'first', 'thought', 'data', 'silly', 'processing', 'array', 'faster', 'processing', 'code', 'independent', 'term', 'matter', 'followup', 'amp', 'effect', 'different', 'late', 'compiler', 'option', 'processing', 'array', 'speed', 'processing', 'array', 'modern', 'optimization', 'flag', 'code', 'slower']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNEMrm8wcJPe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "309dda63-4470-4207-a128-4bbd658a23e2"
      },
      "source": [
        "# Create Dictionary\n",
        "id2word = corpora.Dictionary(data_lemmatized)\n",
        "\n",
        "# Create Corpus\n",
        "texts = data_lemmatized\n",
        "\n",
        "# Term Document Frequency\n",
        "corpus = [id2word.doc2bow(text) for text in texts]\n",
        "\n",
        "# View\n",
        "print(corpus[:1])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 5), (5, 1), (6, 1), (7, 1), (8, 2), (9, 4), (10, 2), (11, 1), (12, 1), (13, 8), (14, 1), (15, 2), (16, 1), (17, 1), (18, 1), (19, 2), (20, 2), (21, 1), (22, 1), (23, 1), (24, 2), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 4), (31, 2), (32, 2), (33, 3), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 4), (46, 2), (47, 1), (48, 1), (49, 1), (50, 1), (51, 2), (52, 1), (53, 1), (54, 1), (55, 1), (56, 3), (57, 1), (58, 1), (59, 1), (60, 2), (61, 4), (62, 1), (63, 2), (64, 1), (65, 2), (66, 1), (67, 1), (68, 1)]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "einO9LM9cP_5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b399009d-dc93-4786-8848-f9d7a651ca92"
      },
      "source": [
        "# Human readable format of corpus (term-frequency)\n",
        "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('actually', 1),\n",
              "  ('almost', 1),\n",
              "  ('amp', 1),\n",
              "  ('arg', 1),\n",
              "  ('array', 5),\n",
              "  ('behavior', 1),\n",
              "  ('calculate', 1),\n",
              "  ('class', 1),\n",
              "  ('clock', 2),\n",
              "  ('code', 4),\n",
              "  ('compiler', 2),\n",
              "  ('const', 1),\n",
              "  ('data', 1),\n",
              "  ('datum', 8),\n",
              "  ('different', 1),\n",
              "  ('double', 2),\n",
              "  ('effect', 1),\n",
              "  ('elapsedtime', 1),\n",
              "  ('extreme', 1),\n",
              "  ('fast', 2),\n",
              "  ('faster', 2),\n",
              "  ('first', 1),\n",
              "  ('flag', 1),\n",
              "  ('followup', 1),\n",
              "  ('generate', 2),\n",
              "  ('independent', 1),\n",
              "  ('initially', 1),\n",
              "  ('int', 1),\n",
              "  ('late', 1),\n",
              "  ('less', 1),\n",
              "  ('long', 4),\n",
              "  ('loop', 2),\n",
              "  ('lt', 2),\n",
              "  ('main', 3),\n",
              "  ('matter', 1),\n",
              "  ('miraculously', 1),\n",
              "  ('modern', 1),\n",
              "  ('nanotime', 1),\n",
              "  ('next', 1),\n",
              "  ('optimization', 1),\n",
              "  ('option', 1),\n",
              "  ('pass', 1),\n",
              "  ('peculiar', 1),\n",
              "  ('piece', 1),\n",
              "  ('println', 1),\n",
              "  ('processing', 4),\n",
              "  ('public', 2),\n",
              "  ('random', 1),\n",
              "  ('reason', 1),\n",
              "  ('region', 1),\n",
              "  ('result', 1),\n",
              "  ('second', 2),\n",
              "  ('silly', 1),\n",
              "  ('similar', 1),\n",
              "  ('slower', 1),\n",
              "  ('speed', 1),\n",
              "  ('start', 3),\n",
              "  ('static', 1),\n",
              "  ('strange', 1),\n",
              "  ('string', 1),\n",
              "  ('sum', 2),\n",
              "  ('system', 4),\n",
              "  ('term', 1),\n",
              "  ('test', 2),\n",
              "  ('thought', 1),\n",
              "  ('time', 2),\n",
              "  ('unknown', 1),\n",
              "  ('void', 1),\n",
              "  ('worth', 1)]]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZDEx8VFcW1E"
      },
      "source": [
        "# Build LDA model\n",
        "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
        "                                           id2word=id2word,\n",
        "                                           num_topics=20, \n",
        "                                           random_state=100,\n",
        "                                           update_every=1,\n",
        "                                           chunksize=100,\n",
        "                                           passes=10,\n",
        "                                           alpha='auto',\n",
        "                                           per_word_topics=True)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wVi8Oc7ciR-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a4a98e8-2985-46c4-e995-b41c23c5efb0"
      },
      "source": [
        "# Print the Keyword in the 10 topics\n",
        "pprint(lda_model.print_topics())\n",
        "doc_lda = lda_model[corpus]"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0,\n",
            "  '0.109*\"item\" + 0.093*\"print\" + 0.081*\"index\" + 0.074*\"run\" + 0.066*\"format\" '\n",
            "  '+ 0.063*\"size\" + 0.054*\"reference\" + 0.051*\"loop\" + 0.050*\"bit\" + '\n",
            "  '0.046*\"standard\"'),\n",
            " (1,\n",
            "  '0.146*\"branch\" + 0.134*\"server\" + 0.100*\"local\" + 0.095*\"repository\" + '\n",
            "  '0.081*\"import\" + 0.065*\"remote\" + 0.050*\"side\" + 0.042*\"design\" + '\n",
            "  '0.019*\"git\" + 0.017*\"necessary\"'),\n",
            " (2,\n",
            "  '0.147*\"list\" + 0.073*\"table\" + 0.072*\"message\" + 0.062*\"update\" + '\n",
            "  '0.051*\"point\" + 0.047*\"select\" + 0.045*\"commit\" + 0.039*\"process\" + '\n",
            "  '0.034*\"set\" + 0.033*\"row\"'),\n",
            " (3,\n",
            "  '0.103*\"field\" + 0.095*\"certain\" + 0.081*\"color\" + 0.054*\"performance\" + '\n",
            "  '0.053*\"suggestion\" + 0.050*\"red\" + 0.048*\"background\" + 0.037*\"closure\" + '\n",
            "  '0.037*\"sign\" + 0.035*\"conversion\"'),\n",
            " (4,\n",
            "  '0.067*\"also\" + 0.061*\"question\" + 0.051*\"application\" + 0.047*\"however\" + '\n",
            "  '0.043*\"different\" + 0.033*\"content\" + 0.026*\"issue\" + 0.025*\"form\" + '\n",
            "  '0.023*\"answer\" + 0.022*\"wrong\"'),\n",
            " (5,\n",
            "  '0.129*\"command\" + 0.089*\"true\" + 0.068*\"really\" + 0.065*\"package\" + '\n",
            "  '0.063*\"false\" + 0.052*\"default\" + 0.052*\"check\" + 0.051*\"lot\" + '\n",
            "  '0.050*\"private\" + 0.028*\"expression\"'),\n",
            " (6,\n",
            "  '0.237*\"element\" + 0.194*\"difference\" + 0.070*\"documentation\" + '\n",
            "  '0.057*\"docker\" + 0.052*\"show\" + 0.046*\"environment\" + 0.033*\"term\" + '\n",
            "  '0.032*\"software\" + 0.022*\"production\" + 0.015*\"period\"'),\n",
            " (7,\n",
            "  '0.161*\"example\" + 0.136*\"string\" + 0.069*\"first\" + 0.068*\"character\" + '\n",
            "  '0.061*\"case\" + 0.043*\"right\" + 0.028*\"available\" + 0.027*\"edit\" + '\n",
            "  '0.026*\"end\" + 0.026*\"single\"'),\n",
            " (8,\n",
            "  '0.310*\"file\" + 0.132*\"name\" + 0.066*\"image\" + 0.065*\"path\" + 0.059*\"script\" '\n",
            "  '+ 0.051*\"project\" + 0.045*\"directory\" + 0.036*\"library\" + 0.026*\"source\" + '\n",
            "  '0.023*\"want\"'),\n",
            " (9,\n",
            "  '0.149*\"change\" + 0.145*\"possible\" + 0.129*\"output\" + 0.086*\"property\" + '\n",
            "  '0.054*\"word\" + 0.048*\"state\" + 0.046*\"jquery\" + 0.040*\"tool\" + '\n",
            "  '0.032*\"action\" + 0.026*\"match\"'),\n",
            " (10,\n",
            "  '0.192*\"type\" + 0.116*\"com\" + 0.107*\"input\" + 0.082*\"request\" + 0.055*\"http\" '\n",
            "  '+ 0.053*\"browser\" + 0.042*\"resource\" + 0.041*\"post\" + 0.036*\"server\" + '\n",
            "  '0.028*\"probably\"'),\n",
            " (11,\n",
            "  '0.166*\"way\" + 0.076*\"text\" + 0.069*\"user\" + 0.060*\"good\" + 0.051*\"number\" + '\n",
            "  '0.044*\"solution\" + 0.044*\"well\" + 0.038*\"option\" + 0.037*\"css\" + '\n",
            "  '0.035*\"page\"'),\n",
            " (12,\n",
            "  '0.276*\"simple\" + 0.131*\"instance\" + 0.081*\"little\" + 0.069*\"behavior\" + '\n",
            "  '0.053*\"matter\" + 0.039*\"definition\" + 0.015*\"silly\" + 0.006*\"incorrect\" + '\n",
            "  '0.005*\"eye\" + 0.000*\"formal\"'),\n",
            " (13,\n",
            "  '0.480*\"object\" + 0.089*\"simply\" + 0.073*\"body\" + 0.000*\"view\" + '\n",
            "  '0.000*\"task\" + 0.000*\"map\" + 0.000*\"auction\" + 0.000*\"event\" + '\n",
            "  '0.000*\"factory\" + 0.000*\"sqlite\"'),\n",
            " (14,\n",
            "  '0.286*\"datum\" + 0.115*\"array\" + 0.077*\"already\" + 0.066*\"data\" + '\n",
            "  '0.039*\"framework\" + 0.037*\"delete\" + 0.031*\"core\" + 0.029*\"equivalent\" + '\n",
            "  '0.028*\"push\" + 0.027*\"next\"'),\n",
            " (15,\n",
            "  '0.109*\"code\" + 0.103*\"line\" + 0.095*\"error\" + 0.062*\"time\" + '\n",
            "  '0.044*\"problem\" + 0.038*\"thing\" + 0.036*\"android\" + 0.035*\"program\" + '\n",
            "  '0.029*\"style\" + 0.026*\"still\"'),\n",
            " (16,\n",
            "  '0.324*\"version\" + 0.148*\"part\" + 0.053*\"group\" + 0.051*\"previous\" + '\n",
            "  '0.043*\"unable\" + 0.028*\"explanation\" + 0.026*\"pass\" + 0.022*\"obvious\" + '\n",
            "  '0.013*\"revision\" + 0.012*\"read\"'),\n",
            " (17,\n",
            "  '0.140*\"class\" + 0.108*\"method\" + 0.070*\"test\" + 0.060*\"system\" + '\n",
            "  '0.054*\"public\" + 0.044*\"static\" + 0.041*\"main\" + 0.040*\"int\" + '\n",
            "  '0.034*\"second\" + 0.030*\"long\"'),\n",
            " (18,\n",
            "  '0.186*\"quot\" + 0.137*\"null\" + 0.084*\"filename\" + 0.079*\"open\" + '\n",
            "  '0.064*\"thank\" + 0.054*\"automatically\" + 0.030*\"somehow\" + 0.027*\"elegant\" + '\n",
            "  '0.020*\"together\" + 0.019*\"alternative\"'),\n",
            " (19,\n",
            "  '0.121*\"function\" + 0.117*\"value\" + 0.097*\"new\" + 0.059*\"work\" + '\n",
            "  '0.046*\"result\" + 0.043*\"return\" + 0.041*\"key\" + 0.035*\"able\" + '\n",
            "  '0.032*\"variable\" + 0.031*\"var\"')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3WyenEMck3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "089d1614-9e7e-4e4c-bc82-f4f0fdb1d4b1"
      },
      "source": [
        "# Compute Perplexity\n",
        "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
        "\n",
        "# Compute Coherence Score\n",
        "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Perplexity:  -14.225221347247492\n",
            "\n",
            "Coherence Score:  0.40074780391333203\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtFay85WcP3q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "outputId": "72be47f4-3105-4d41-cb3a-5886bd659a0a"
      },
      "source": [
        "# Visualize the topics\n",
        "pyLDAvis.enable_notebook()\n",
        "vis = gensimvis.prepare(lda_model, corpus, id2word)\n",
        "vis"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-c7d109a39b34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Visualize the topics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mvis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensimvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlda_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mvis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyLDAvis/gensim_models.py\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(topic_model, corpus, dictionary, doc_topic_dist, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \"\"\"\n\u001b[1;32m    122\u001b[0m     \u001b[0mopts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_extract_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_topic_dist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyLDAvis/_prepare.py\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(topic_term_dists, doc_topic_dists, doc_lengths, vocab, term_frequency, R, lambda_step, mds, n_jobs, plot_opts, sort_topics, start_index)\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0mdoc_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_series_with_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'doc_length'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_series_with_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'vocab'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m     \u001b[0m_input_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_term_dists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_topic_dists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterm_frequency\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m     \u001b[0mR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyLDAvis/_prepare.py\u001b[0m in \u001b[0;36m_input_validate\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_input_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_input_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValidationError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m' * '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyLDAvis/_prepare.py\u001b[0m in \u001b[0;36m_input_check\u001b[0;34m(topic_term_dists, doc_topic_dists, doc_lengths, vocab, term_frequency)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0merr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0m__num_dist_rows__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_term_dists\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mttds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0merr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Not all rows (distributions) in topic_term_dists sum to 1.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyLDAvis/_prepare.py\u001b[0m in \u001b[0;36m__num_dist_rows__\u001b[0;34m(array, ndigits)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m__num_dist_rows__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndigits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/ops/common.py\u001b[0m in \u001b[0;36mnew_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     63\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/ops/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0;31m#  to avoid constructing two potentially large/sparse DataFrames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m     join_columns, _, _ = left.columns.join(\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"outer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_indexers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m     )\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0mrvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_wrapped_if_datetimelike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     \u001b[0mrvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_from_zerodim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;31m# TODO: same for tuples?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36mna_arithmetic_op\u001b[0;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_na_arithmetic_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_cmp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \"\"\"\n\u001b[0;32m--> 140\u001b[0;31m     \u001b[0mReturn\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mresult\u001b[0m \u001b[0mof\u001b[0m \u001b[0mevaluating\u001b[0m \u001b[0mop\u001b[0m \u001b[0mon\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0mIf\u001b[0m \u001b[0mnative\u001b[0m \u001b[0mtypes\u001b[0m \u001b[0mare\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcompatible\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mtry\u001b[0m \u001b[0mcoercion\u001b[0m \u001b[0mto\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_typing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFuncType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomputation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNUMEXPR_INSTALLED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mroperator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/computation/check.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optional\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimport_optional_dependency\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mne\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimport_optional_dependency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"numexpr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"warn\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mNUMEXPR_INSTALLED\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mne\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mNUMEXPR_INSTALLED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: import_optional_dependency() got an unexpected keyword argument 'errors'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_wdx3sF4hJj"
      },
      "source": [
        "# Install java\n",
        "def install_java():\n",
        "  !apt-get install -y openjdk-8-jdk-headless -qq > /dev/null      #install openjdk\n",
        "  os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"     #set environment variable\n",
        "  !java -version       #check java version\n",
        "install_java()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXUiPwxB7sTF"
      },
      "source": [
        "# Install mallet\n",
        "!wget http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\n",
        "!unzip mallet-2.0.8.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ro5CR6z87x34"
      },
      "source": [
        "mallet_path = '/content/mallet-2.0.8/bin/mallet'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yN_0mWjr2v_d"
      },
      "source": [
        "ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=20, id2word=id2word)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OAMJPCVszZZ"
      },
      "source": [
        "# Show Topics\n",
        "pprint(ldamallet.show_topics(formatted=False))\n",
        "\n",
        "# Compute Coherence Score\n",
        "coherence_model_ldamallet = CoherenceModel(model=ldamallet, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
        "coherence_ldamallet = coherence_model_ldamallet.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_ldamallet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "92bbda91-7f8a-44f0-8888-d9b30924e816",
        "_cell_guid": "fce979f6-5607-4d95-ab8e-c6d9a130a293",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true,
        "id": "M1BkvDE0T3b6"
      },
      "source": [
        "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
        "    \"\"\"\n",
        "    Compute c_v coherence for various number of topics\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    dictionary : Gensim dictionary\n",
        "    corpus : Gensim corpus\n",
        "    texts : List of input texts\n",
        "    limit : Max num of topics\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "    model_list : List of LDA topic models\n",
        "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
        "    \"\"\"\n",
        "    coherence_values = []\n",
        "    model_list = []\n",
        "    for num_topics in range(start, limit, step):\n",
        "        model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
        "        model_list.append(model)\n",
        "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
        "        coherence_values.append(coherencemodel.get_coherence())\n",
        "\n",
        "    return model_list, coherence_values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlAhvGIPdmjw"
      },
      "source": [
        "# Can take a long time to run.\n",
        "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=data_lemmatized, start=2, limit=20, step=6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIgH2J1VfnN7"
      },
      "source": [
        "# Show graph\n",
        "limit=20; start=2; step=6;\n",
        "x = range(start, limit, step)\n",
        "plt.plot(x, coherence_values)\n",
        "plt.xlabel(\"Num Topics\")\n",
        "plt.ylabel(\"Coherence score\")\n",
        "plt.legend((\"coherence_values\"), loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqvrD2WN9IGp"
      },
      "source": [
        "# Print the coherence scores\n",
        "for m, cv in zip(x, coherence_values):\n",
        "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFg07epQ9Kq5"
      },
      "source": [
        "# Select the model and print the topics\n",
        "optimal_model = model_list[2]\n",
        "model_topics = optimal_model.show_topics(formatted=False)\n",
        "pprint(optimal_model.print_topics(num_words=10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SEYr4gr9P19"
      },
      "source": [
        "def format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=texts):\n",
        "    # Init output\n",
        "    sent_topics_df = pd.DataFrame()\n",
        "\n",
        "    # Get main topic in each document\n",
        "    for i, row in enumerate(ldamodel[corpus]):\n",
        "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
        "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
        "        for j, (topic_num, prop_topic) in enumerate(row):\n",
        "            if j == 0:  # => dominant topic\n",
        "                wp = ldamodel.show_topic(topic_num)\n",
        "                topic_keywords = \", \".join([word for word, prop in wp])\n",
        "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
        "            else:\n",
        "                break\n",
        "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
        "\n",
        "    # Add original text to the end of the output\n",
        "    contents = pd.Series(texts)\n",
        "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
        "\n",
        "    return(sent_topics_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJlRrD__AaQQ"
      },
      "source": [
        "df_topic_sents_keywords = format_topics_sentences(ldamodel=optimal_model, corpus=corpus, texts=texts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpfzBTWGAxPg"
      },
      "source": [
        "# Format\n",
        "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
        "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
        "\n",
        "# Show\n",
        "df_dominant_topic.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mx-pFBBqA0b_"
      },
      "source": [
        "# Group top 5 sentences under each topic\n",
        "sent_topics_sorteddf_mallet = pd.DataFrame()\n",
        "\n",
        "sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
        "\n",
        "for i, grp in sent_topics_outdf_grpd:\n",
        "    sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet, \n",
        "                                             grp.sort_values(['Perc_Contribution'], ascending=[0]).head(1)], \n",
        "                                            axis=0)\n",
        "\n",
        "# Reset Index    \n",
        "sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Format\n",
        "sent_topics_sorteddf_mallet.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Text\"]\n",
        "\n",
        "# Show\n",
        "sent_topics_sorteddf_mallet.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuIHu4lIA7xu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}